# 深入研究策略梯度算法中的无效动作屏蔽

## 摘要

近年来，深度强化学习算法在许多具有挑战性的测出来游戏中取得了良好的表现。然而在游戏中，从学习策略预测的完整离散行为分布中采样的动作很可能是无效的（例如：撞墙）。在策略梯度算法中，处理这个问题的通常方法是“屏蔽”无效的动作，只从有效的动作集合中进行采样。然而，这一影响仍未得到充分的研究。在本文中，我们展示了这种实践的理论依据，从经验的角度证明了它的重要性。并通过评估不同的行动屏蔽机制，如何使用屏蔽训练后去除屏蔽，提供了进一步的见解。